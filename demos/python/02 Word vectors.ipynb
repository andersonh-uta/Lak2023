{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8424ede8-61b6-46e9-8d11-66b7e0bd4e59",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "Word embeddings were all the rage from about 2013 (when the `word2vec` algorithm was published) through 2018 (when BERT was published and changed the entire field overnight).  Word vectors tend to have a lot of advantages over bag of words models:\n",
    "\n",
    "- They encode texts _densely._  This tends to mean less chance of over-fitting a model, and that most models will train far more quickly.\n",
    "- They can encode _degrees of similarity_ between word.  Bag-of-word treats all word features as orthogonal (\"cat\" and \"dog\" are as different as \"cat\" and \"cats\").  Word embeddings project these word into lower-dimensional spaces.\n",
    "- They are _pretrained lookup tables_ that map words to fixed-length, dense vectors.  This means they can be trained once and re-used many times--a sort of primitive transfer learning.\n",
    "- They can learn about the _co-occurrence patterns_ of words, which ends up being a _very_ good proxy for the \"meaning\" of words.  (and since this is derived purely from the data you provide, you can easily learn domain-specific or context-specific representations).\n",
    "\n",
    "However, this training process can take some time if you have a lot of data. And you usually need a decent amount of data to train these in the first place--a good rule of thumb is \"about a million\" words is where it starts making sense to train your own vectors.\n",
    "\n",
    "There are several algorithms for word embeddings, but the biggest by far are:\n",
    "- Latent Semantic Analysis (aka Latent Semantic Indexing): build a document-term matrix, then run Singular Value Decomposition to reduce it down to fewer dimensions.  Fast, generally works well, but doesn't encode as much information as the other options.\n",
    "- Word2Vec: learns to encode words based on what other words they occur around.  Can be easily run on moderately sized datasets and can learn very high-quality vectors.\n",
    "- Global Vectors (GloVe): technically different from Word2Vec but most of that is implementation details.  There's rarely any meaningful difference in the quality of the vector between GloVe and Word2Vec.\n",
    "- FastText: FastText is designed to capture sub-word inforation (e.g., morphology).  It can theoretically have good representations of brand new out-of-vocabulary vocabulary items.  In practice it tends to perform pretty similar to Word2Vec/GloVe for English, but FastText can work better for languages with lots of inflection information (e.g., Turkish).\n",
    "- Having an embedding layer as part of a neural network that learns good embeddings for your specific task.  (this is basically a fancy way of training your own using word2vec, but by coupling the vector training much more tightly and explicitly to your particular task).\n",
    "\n",
    "In this notebook we'll use the same data and prediction task as the Bag of Words notebook--predict the number of stars from an amazon review--but this time using a pretty simple neural network.  (word embeddings + neural networks, or random forests, or XGBoost, or the like is usually a very good combination!).  There are two main ways to use word vectors.  First option: convert each document into a 2d array (one row per word, one column per embedding dimension), then use something like a Convolutional Neural Network or LSTM.  This tends to provide a lot of very rich information, since this kind of representation with these kinds of models can learn something about conextual representations of each word.  Second option: convert each document into a single vector by summing or averaging the individual word vectors.  This is usually a good \"first draft\" since it's easy, and lightens the computational load that your model has to pick up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013f326-2dc5-4b24-9ff9-c9f45669af78",
   "metadata": {},
   "source": [
    "# Using pre-trained word vectors\n",
    "\n",
    "Most of the time, you can grab someone else's pre-trained vectors and just use those.  spaCy has such vectors ready to go for us, but we need to be using one of the `*_lg` models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f6f4c7-335c-42be-ab6b-83986439abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "# !conda install --yes tqdm pandas scikit-learn spacy\n",
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "# NOTE: replace this next line with the platform-specific instructions\n",
    "# for your system from: https://pytorch.org/get-started/locally/\n",
    "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31482100-f79b-47e5-a600-bbc82bf1fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm is a magic library that gives you progerss bars when iterating\n",
    "# through things.\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# register tqdm with pandas so we can get .progress_apply() method\n",
    "# added to dataframes.  This is a version of pd.DataFrame.apply()\n",
    "# but now it prints a progress bar!\n",
    "tqdm.pandas(smoothing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030e6ab6-1002-40c4-bbd6-91813a14e66e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_0964290</td>\n",
       "      <td>product_en_0740675</td>\n",
       "      <td>reviewer_en_0342986</td>\n",
       "      <td>1</td>\n",
       "      <td>Arrived broken. Manufacturer defect. Two of th...</td>\n",
       "      <td>I'll spend twice the amount of time boxing up ...</td>\n",
       "      <td>en</td>\n",
       "      <td>furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_0690095</td>\n",
       "      <td>product_en_0440378</td>\n",
       "      <td>reviewer_en_0133349</td>\n",
       "      <td>1</td>\n",
       "      <td>the cabinet dot were all detached from backing...</td>\n",
       "      <td>Not use able</td>\n",
       "      <td>en</td>\n",
       "      <td>home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_0311558</td>\n",
       "      <td>product_en_0399702</td>\n",
       "      <td>reviewer_en_0152034</td>\n",
       "      <td>1</td>\n",
       "      <td>I received my first order of this product and ...</td>\n",
       "      <td>The product is junk.</td>\n",
       "      <td>en</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_0044972</td>\n",
       "      <td>product_en_0444063</td>\n",
       "      <td>reviewer_en_0656967</td>\n",
       "      <td>1</td>\n",
       "      <td>This product is a piece of shit. Do not buy. D...</td>\n",
       "      <td>Fucking waste of money</td>\n",
       "      <td>en</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en_0784379</td>\n",
       "      <td>product_en_0139353</td>\n",
       "      <td>reviewer_en_0757638</td>\n",
       "      <td>1</td>\n",
       "      <td>went through 3 in one day doesn't fit correct ...</td>\n",
       "      <td>bubble</td>\n",
       "      <td>en</td>\n",
       "      <td>pc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id          product_id          reviewer_id  stars  \\\n",
       "0  en_0964290  product_en_0740675  reviewer_en_0342986      1   \n",
       "1  en_0690095  product_en_0440378  reviewer_en_0133349      1   \n",
       "2  en_0311558  product_en_0399702  reviewer_en_0152034      1   \n",
       "3  en_0044972  product_en_0444063  reviewer_en_0656967      1   \n",
       "4  en_0784379  product_en_0139353  reviewer_en_0757638      1   \n",
       "\n",
       "                                         review_body  \\\n",
       "0  Arrived broken. Manufacturer defect. Two of th...   \n",
       "1  the cabinet dot were all detached from backing...   \n",
       "2  I received my first order of this product and ...   \n",
       "3  This product is a piece of shit. Do not buy. D...   \n",
       "4  went through 3 in one day doesn't fit correct ...   \n",
       "\n",
       "                                        review_title language  \\\n",
       "0  I'll spend twice the amount of time boxing up ...       en   \n",
       "1                                       Not use able       en   \n",
       "2                               The product is junk.       en   \n",
       "3                             Fucking waste of money       en   \n",
       "4                                             bubble       en   \n",
       "\n",
       "   product_category  \n",
       "0         furniture  \n",
       "1  home_improvement  \n",
       "2              home  \n",
       "3          wireless  \n",
       "4                pc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "train = pd.read_csv(\"../../data/train.csv\")\n",
    "test = pd.read_csv(\"../../data/test.csv\")\n",
    "val = pd.read_csv(\"../../data/validation.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d5d16c4-ecda-42c7-8750-a5353ec0e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263f5620-54e7-42fe-b08b-30636afb611e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35183849c2794bb3b054c1bfc6650658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.02563680e-03  1.53662562e-01 -1.67447686e-01 -7.95046240e-02\n",
      "  6.34283647e-02 -1.13214003e-02 -1.16581870e-02 -1.14358470e-01\n",
      " -4.93131531e-03  2.15048170e+00 -1.38603300e-01  9.16635990e-02\n",
      "  1.21868968e-01 -4.79591042e-02 -1.14931360e-01 -6.06204830e-02\n",
      " -6.53301701e-02  1.24221015e+00 -1.92374930e-01  1.43992379e-02\n",
      "  3.97625677e-02 -2.04175301e-02 -5.10083996e-02 -2.18137261e-02\n",
      " -2.08333917e-02  1.33769875e-02 -1.01538457e-01 -1.31367564e-01\n",
      "  3.57617773e-02 -8.36472362e-02 -8.32881927e-02  8.36016834e-02\n",
      " -3.25288437e-02  9.63581651e-02  6.59466237e-02 -5.85295893e-02\n",
      "  1.67492833e-02  7.65056163e-02 -4.94824238e-02 -1.13120914e-01\n",
      "  4.69577452e-03  1.08310066e-01  2.43635625e-02 -6.97399229e-02\n",
      "  4.36965227e-02  4.03517336e-02 -1.68145776e-01 -1.90215465e-02\n",
      " -3.84692363e-02  2.51397491e-02 -1.24465981e-02 -1.72056016e-02\n",
      "  5.86093497e-03 -2.24877838e-02  3.24918181e-02 -1.33547625e-02\n",
      " -2.76379548e-02 -1.10679857e-01 -8.30884837e-03 -4.57795300e-02\n",
      " -4.39137295e-02 -2.24953741e-02 -4.20155302e-02  1.91653267e-01\n",
      "  3.10086254e-02 -5.91732487e-02  1.01313647e-02  1.42835556e-02\n",
      "  2.84825880e-02  1.53597504e-01  1.04105152e-01  6.46434799e-02\n",
      "  1.92874312e-01  5.26455510e-03  1.20747507e-01  4.18454297e-02\n",
      "  5.67143783e-02 -5.41098937e-02 -5.21209054e-02  1.26579180e-01\n",
      "  3.64925736e-03  9.20500308e-02 -1.60486490e-01 -3.06827091e-02\n",
      " -7.58270780e-03 -2.02639237e-01  7.29970559e-02 -8.00306350e-02\n",
      "  2.44426996e-01  8.43205303e-02 -8.89091566e-02  1.03142569e-02\n",
      " -1.06802128e-01  5.90884425e-02  1.25323936e-01 -9.71930567e-03\n",
      "  2.93905046e-02 -8.18878561e-02 -3.67970043e-03  5.39106503e-03\n",
      " -8.88798945e-03 -4.45985571e-02 -6.11367822e-02 -3.42710689e-02\n",
      "  1.24672376e-01 -7.97008276e-01  1.36246189e-01 -1.97850429e-02\n",
      "  6.41880110e-02 -1.69209465e-02  2.80618034e-02 -1.48693979e-01\n",
      "  1.20177329e-01 -1.15595721e-01  4.32040244e-02 -4.67709266e-02\n",
      "  2.67749862e-03  4.90682013e-02 -1.57143660e-02  7.67398532e-03\n",
      "  5.10377698e-02 -6.68546483e-02 -1.12344678e-02  3.90583873e-02\n",
      " -1.93643058e-03  6.37212172e-02 -3.80401872e-02 -1.42530441e-01\n",
      "  6.22276366e-02  2.96987314e-02 -2.18185410e-02  1.93782356e-02\n",
      " -1.51244566e-01  6.41915351e-02  1.31870493e-01  3.35573778e-02\n",
      " -1.23160817e-02  4.19583507e-02  1.92752350e-02 -5.84953502e-02\n",
      " -1.27762246e+00  9.82269570e-02  9.42827016e-02  2.65838718e-03\n",
      "  3.68819349e-02 -5.18987663e-02 -1.01057291e-01  6.04316369e-02\n",
      "  6.26650825e-02 -6.23726025e-02 -3.51270773e-02  5.02564237e-02\n",
      "  8.24057311e-02 -5.70007658e-04 -3.34838368e-02 -1.33061241e-02\n",
      " -6.39586896e-02  5.27910283e-03 -3.59847471e-02 -4.47234958e-02\n",
      " -4.05290052e-02  4.75496091e-02 -6.84200227e-02 -6.11006431e-02\n",
      " -5.66377863e-02 -1.15540251e-01  7.09979162e-02 -1.25471307e-02\n",
      "  1.54557541e-01 -5.74955065e-03 -4.23819060e-03 -9.38031077e-02\n",
      "  1.17916055e-02 -8.00791904e-02 -1.01787440e-01  2.14266330e-02\n",
      " -2.88428552e-02  4.87053916e-02  6.81724341e-04 -8.52300823e-02\n",
      " -1.01718139e-02 -6.80693388e-02 -1.22291215e-01 -8.89471844e-02\n",
      " -5.26234284e-02 -3.13305780e-02 -4.02294323e-02 -6.12855069e-02\n",
      "  5.41420393e-02  7.43286237e-02 -7.56700244e-03 -1.95492841e-02\n",
      " -7.00496137e-02  5.27253188e-02  3.70037854e-02  1.07493229e-01\n",
      " -1.23260766e-02 -9.77190286e-02 -5.44649623e-02  1.73026994e-01\n",
      " -7.67502049e-03 -1.30492281e-02 -8.14451128e-02 -3.91158741e-03\n",
      "  2.09870949e-01  8.56938511e-02  2.02790312e-02 -1.03636086e-02\n",
      " -1.89642385e-02  4.68334295e-02 -2.61872429e-02 -1.71526112e-02\n",
      " -7.72974864e-02 -1.56099752e-01  5.87679483e-02  1.50816485e-01\n",
      " -7.81039149e-02  8.64735432e-03 -1.76252261e-01  2.30101217e-02\n",
      " -3.13619561e-02 -4.84452024e-02 -4.41798531e-02  5.97371459e-02\n",
      " -1.07368231e-02  1.12159569e-02 -7.62619544e-03  1.16941035e-01\n",
      "  1.71802547e-02  3.11490539e-02 -1.26535445e-01 -2.58338470e-02\n",
      "  1.19185805e-01  8.89161229e-02 -4.85632233e-02 -8.07733387e-02\n",
      "  2.61060875e-02 -4.69908789e-02 -9.23466459e-02  7.97213688e-02\n",
      "  5.46609573e-02  6.39136881e-02  2.50302767e-03  1.19971685e-01\n",
      "  1.04354307e-01 -1.71822742e-01 -8.19069147e-02 -1.18188426e-01\n",
      " -1.19661443e-01  1.69694260e-01  1.90491509e-02 -7.54292235e-02\n",
      " -1.36398776e-02 -4.02476527e-02  6.07211627e-02  2.18190834e-01\n",
      "  1.06604621e-01 -5.18531650e-02 -4.35200967e-02  5.47711700e-02\n",
      "  1.39868870e-01  1.32537410e-01 -3.83616276e-02  6.95076212e-02\n",
      "  7.57630542e-02 -4.20360975e-02 -1.56852808e-02  2.55472735e-02\n",
      "  3.77468824e-01  9.37980134e-03  1.64188534e-01 -4.69442233e-02\n",
      " -6.64579272e-02 -1.50204435e-01 -8.33438262e-02  6.83091655e-02\n",
      "  1.52374059e-02  8.41615647e-02 -1.35327296e-04  1.58425719e-01\n",
      "  1.85610637e-01  1.36414850e-02  2.45107356e-02 -5.44850715e-02\n",
      " -1.00722946e-01 -1.51673689e-01  7.03100041e-02 -4.68887873e-02\n",
      "  1.16764568e-01 -8.70073289e-02 -2.04796508e-01  2.77629066e-02\n",
      "  2.05837027e-03 -8.80814418e-02 -2.39794664e-02 -2.14166380e-02\n",
      " -4.14964408e-02 -2.19122823e-02  7.79750012e-03  9.19015706e-02]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def text2array(docs, nlp):\n",
    "    # if all we need is vectors, we can use nlp.make_doc()\n",
    "    # for a pretty big speedup.  This will basically just do\n",
    "    # tokenization, case normalization, and vector lookups.\n",
    "    return np.array([\n",
    "        i.vector\n",
    "        for i in map(nlp.make_doc, tqdm(docs, smoothing=0))\n",
    "    ])\n",
    "\n",
    "train_docs = text2array(train[\"review_body\"], nlp)\n",
    "print(train_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f466cc3-2a28-4f06-977d-ca62623424ea",
   "metadata": {},
   "source": [
    "...and that's it.  Now let's just do the same to the training and validation sets, then throw a small multi-layer perceptron at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6864c0b4-f53e-48a3-b756-dc492124d125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9db31f84d344138d47cfb922b21165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06e6b6c730a4f7a86b10a4d94d1c639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_docs = text2array(test[\"review_body\"], nlp)\n",
    "val_docs = text2array(val[\"review_body\"], nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119c7b9-ad08-408e-8e46-2c150dd78fc8",
   "metadata": {},
   "source": [
    "# PyTorch model\n",
    "\n",
    "We'll use PyTorch to build a pretty basic multi-layer perceptron: 3 layers, of size 128, 64, and 64.  If you're not familiar with PyTorch, don't worry about the code in the next few cells; PyTorch gives you a lot more control over the nitty-gritty details of the training process, but none of the steps are especially complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43790ef7-5105-4c24-ba74-5732860ace7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# We'll want our data to be in a particular format to ease the\n",
    "# batching logic.\n",
    "def prepare_dataset(x, y):\n",
    "    x = torch.Tensor(x)\n",
    "    y = torch.Tensor(pd.get_dummies(y[\"stars\"]).values)\n",
    "    return DataLoader(\n",
    "        TensorDataset(x, y),\n",
    "        # this dataset isn't very sensitive to batch size, so let's\n",
    "        # pick a big one to let us iterate more quickly.\n",
    "        batch_size=512,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "train_torch = prepare_dataset(train_docs, train)\n",
    "test_torch = prepare_dataset(test_docs, test)\n",
    "val_torch = prepare_dataset(val_docs, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b575d45-1c6f-4126-9f6c-b635f1b2f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if available\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c0c039-94b1-401c-a80a-fbb790c1f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# training loop\n",
    "def training_loop(\n",
    "    model,\n",
    "    training_dataset,\n",
    "    validation_dataset,\n",
    "):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # trackers for early stopping--5 rounds with no improvement\n",
    "    # before stopping.\n",
    "    best_val_loss = np.inf\n",
    "    early_stopping_counter = 0\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        for (x, y) in tqdm(training_dataset, desc=f\"Epoch {epoch}\"):\n",
    "            # DEVICE is read from outer/global scope; defined in\n",
    "            # previous cell\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            \n",
    "            # learn from batch\n",
    "            opt.zero_grad()\n",
    "            preds = model(x)\n",
    "            loss = loss_fn(preds, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        # validate after each epoch\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        preds = []\n",
    "        ys = []\n",
    "        for (x, y) in validation_dataset:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            # loss-per-sample\n",
    "            preds.append(model(x).to(\"cpu\"))\n",
    "            ys.append(y.to(\"cpu\"))\n",
    "        model.train()\n",
    "        preds = torch.cat(preds)\n",
    "        ys = torch.cat(ys)\n",
    "        val_loss = loss_fn(preds, ys)\n",
    "        \n",
    "        preds = torch.argmax(preds, axis=1).numpy()\n",
    "        ys = torch.argmax(ys, axis=1).numpy()\n",
    "        val_acc = np.mean(preds == ys)\n",
    "        val_f1 = f1_score(preds, ys, average=\"macro\")\n",
    "        print(f\"{val_loss=:.6f} - {val_acc=:.3%} - {val_f1=:.6f}\")\n",
    "        \n",
    "        # check early stopping criteria\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            \n",
    "        if early_stopping_counter >= 5:\n",
    "            break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb3b1095-c420-465a-96b7-2c97979a248a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bd8449b8de43e0b872e335658f5bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.182499 - val_acc=48.560% - val_f1=0.477031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49af19b364cf423dba612e4645316e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.174276 - val_acc=48.660% - val_f1=0.481182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae9efb6bcf648f0b0dcc58d9761ae67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.163337 - val_acc=49.440% - val_f1=0.483215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8b0ea5fa624547b0a2598cb2297ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.158106 - val_acc=49.660% - val_f1=0.485795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6625b5eef4490d8f8f77b7a1709a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.154734 - val_acc=49.820% - val_f1=0.482703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c8fa8f1b514b129e43ea0dbf89763e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.153258 - val_acc=49.820% - val_f1=0.483122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcc8e9c1f0a40e6b5d47f7708b1e4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.156546 - val_acc=49.960% - val_f1=0.495740\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63612e5269e4576a8e949a2a076c536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.156823 - val_acc=50.040% - val_f1=0.496198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf5ac321969461b91182c6a38dab7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.156470 - val_acc=49.880% - val_f1=0.495189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db1dfe3ef414215a544ef93a1436b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.158228 - val_acc=50.060% - val_f1=0.495088\n"
     ]
    }
   ],
   "source": [
    "# model specification\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.BatchNorm1d(300),\n",
    "    torch.nn.Linear(300, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 5),\n",
    ")\n",
    "model.to(DEVICE)\n",
    "model = training_loop(model, train_torch, val_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8aa2bf6-24eb-4d11-8412-61b2320d65e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test set scores: accuracy=50.06%, f1=0.4951\n"
     ]
    }
   ],
   "source": [
    "# final performance metrics\n",
    "model.eval()\n",
    "preds = []\n",
    "ys = []\n",
    "for (x, y) in val_torch:\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    preds.append(model(x).to(\"cpu\").detach().numpy())\n",
    "    ys.append(y.to(\"cpu\"))\n",
    "preds = np.argmax(np.vstack(preds), axis=1)\n",
    "ys = np.argmax(np.vstack(ys), axis=1)\n",
    "\n",
    "acc = np.mean(preds == ys)\n",
    "f1 = f1_score(preds, ys, average=\"macro\")\n",
    "print(f\"Final test set scores: accuracy={acc:.2%}, f1={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beadea4-d812-4348-b65d-52d01f0a346e",
   "metadata": {},
   "source": [
    "# Train your own word vectors with Gensim\n",
    "\n",
    "One of the things Gensim is designed for is fast implementations of Word2Vec, FastText, and a few other algorithms.  Let's train our own word Word2Vec vectors.  To do this, we just need to get our data into a list of lists of strings (i.e.: a list of tokenized documents).  We'll use spaCy to do our tokenization and string normalization, but we won't lemmatize our texts.\n",
    "\n",
    "For word vectors, we usually want to keep stopwords and such in--they can actually provide really useful co-occurrence information for the embedding algorithm to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417e82d9-d5d2-4599-a4b7-99dba8d6ee4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766560f1a3ca4f4c92808c872b3482ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arrived', 'broken', '.', 'manufacturer', 'defect', '.', 'two', 'of', 'the', 'legs', 'of', 'the', 'base', 'were', 'not', 'completely', 'formed', ',', 'so', 'there', 'was', 'no', 'way', 'to', 'insert', 'the', 'casters', '.', 'i', 'unpackaged', 'the', 'entire', 'chair', 'and', 'hardware', 'before', 'noticing', 'this', '.', 'so', ',', 'i', \"'ll\", 'spend', 'twice', 'the', 'amount', 'of', 'time', 'boxing', 'up', 'the', 'whole', 'useless', 'thing', 'and', 'send', 'it', 'back', 'with', 'a', '1', '-', 'star', 'review', 'of', 'part', 'of', 'a', 'chair', 'i', 'never', 'got', 'to', 'sit', 'in', '.', 'i', 'will', 'go', 'so', 'far', 'as', 'to', 'include', 'a', 'picture', 'of', 'what', 'their', 'injection', 'molding', 'and', 'quality', 'assurance', 'process', 'missed', 'though', '.', 'i', 'will', 'be', 'hesitant', 'to', 'buy', 'again', '.', 'it', 'makes', 'me', 'wonder', 'if', 'there', 'are', \"n't\", 'missing', 'structures', 'and', 'supports', 'that', 'do', \"n't\", 'impede', 'the', 'assembly', 'process', '.']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(s, nlp):\n",
    "    return [tok.lower_ for tok in nlp.make_doc(s)]\n",
    "\n",
    "# we could parallelize this for even more speed, but...eh.\n",
    "docs = pd.concat((\n",
    "    train[\"review_body\"],\n",
    "    test[\"review_body\"],\n",
    "    val[\"review_body\"]\n",
    ")).progress_apply(tokenize, nlp=nlp)\n",
    "docs = list(docs)\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921cfc82-36b3-45a7-84ed-b82f0d769d8d",
   "metadata": {},
   "source": [
    "A quick digression: your choice of preprocessing matters, just like for bag of words models.  E.g.: sometimes you might know that verb tense, or singular versus plural, are generally important.  For really, really large datasets, doing gentler preprocessing is generally a good idea, but here we'll just keep the code simple.  Just make sure you do the same preprocessing to your text before applying your vectors!\n",
    "\n",
    "There's also some advice out there that Word2Vec should be trained on _sentences,_ not _documents,_ but we're just going to ignore that.  It doesn't always matter very much in practice.\n",
    "\n",
    "Now, we just throw the tokenized text into the Gensim Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739f966b-3934-48c5-90fd-6c06fbb1bd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a796b5637d5e47e2bb2914a2e3593900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 1:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4feaa788a47f4f539d04c34a4faa9022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 2:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ca93df98114b049d718cb53ffce5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 3:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadca389440348d38dc5cc8112ff059c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 4:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe60175860c4ff085c14ee2fc6f6e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 5:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c96ffe122524db18bc8be334779f02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 6:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58524b8d62da4265aef0fcbd6aafe5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 7:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a693a33f078e4cfdb47eaff3487e3f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 8:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e320ba7ab543e5bfe680c34b6139e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 9:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fdf408b3634419a4f21a0f66ae046e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 10:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535d11a7bda74eeba178fdeefe98c0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 11:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd73684d89742bcac8bbf8fabeb3b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 12:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c423f57676ba4c1ca98aa4a9997f6297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 13:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c22b772f95048ac9c2f5264f99100d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 14:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7d8d23c107422ca7ac71319856091c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 15:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98512efe008140b184667cca9b28db5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 16:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343d5becd32045f49aa74871c59a2ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 17:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aee2f9b0fba4445895125d6132e1552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 18:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077a0750a1bf4c49a3a142e1de6d31d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 19:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee58f3184ca44017b1d720adc1dcd29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 20:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b459c960c74e9a96f7b0d2d83e1387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 21:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e329de11ec403c8ea47629b5649b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 22:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8358d67868b445abb8d9b6cc5c2e62fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 23:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81973a25c5514960818da925cf87fd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 24:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb3bd66129545d6812ea92a594889d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 25:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f8bd1b0dfc4421bb8e70f82570d1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pass 26:   0%|          | 0.00/210k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "class Corpus:\n",
    "    \"\"\"a class that prints progress as you iterate through it.\n",
    "    like tqdm, but it properly re-initializes the progress bar\n",
    "    after each run through.  I like to use this in place of \n",
    "    once-per-epoch callbacks in Gensim since this provides\n",
    "    more constant and real-time feedback.\"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.n = 1\n",
    "        \n",
    "    def __iter__(self):\n",
    "        yield from tqdm(\n",
    "            self.it,\n",
    "            unit_scale=True,\n",
    "            desc=f\"Pass {self.n}\",\n",
    "            smoothing=0,\n",
    "        )\n",
    "        self.n += 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.it)\n",
    "\n",
    "# there are a LOT of Word2Vec parameters we could tweak, but\n",
    "# we'll leave most of them at their default values.\n",
    "w2v = Word2Vec(\n",
    "    Corpus(docs),\n",
    "    vector_size=300,\n",
    "    # number of parallel CPU threads to use--set this lower or higher\n",
    "    # depending on your system.\n",
    "    workers=10,\n",
    "    # sg=1 to use skip-gram, sg=0 to use CBOW\n",
    "    sg=1,\n",
    "    # hs=1 to use hierarchical softmax, 0 for negative sampling.\n",
    "    hs=0,\n",
    "    # ignore words with frewer than this many total occurences\n",
    "    min_count=5,\n",
    "    # number of passes over the corpus.  More epochs --> better vectors,\n",
    "    # usually, but with diminishing returns.  25 i probably overkill\n",
    "    # for this data but we're gonna do it anyways.\n",
    "    epochs=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "791c0291-a7ce-4095-b163-49a4e6af9a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.37350380e-01 -2.24434271e-01 -1.74850196e-01 -2.67496705e-01\n",
      "  3.61776263e-01 -1.64233074e-01 -2.14357302e-01  2.67212898e-01\n",
      " -3.52885693e-01  5.56278646e-01  7.74217620e-02 -3.47563364e-02\n",
      " -7.70093799e-02 -4.31601435e-01  6.47711754e-02 -1.04609817e-01\n",
      " -4.85226996e-02  2.40687534e-01  2.02059209e-01  1.61600158e-01\n",
      "  4.61019456e-01  3.08313966e-01 -1.41286567e-01  1.62408158e-01\n",
      " -1.55187503e-01  6.64419115e-01 -2.24275072e-03  4.54806477e-01\n",
      " -1.90380186e-01 -4.09426123e-01 -1.70356572e-01 -3.28126967e-01\n",
      "  2.58329033e-04 -6.68878406e-02  2.92585306e-02 -1.12499088e-01\n",
      "  2.53223404e-02  2.41018832e-01  2.34994560e-01  2.32210174e-01\n",
      "  1.69653460e-01 -1.63170859e-01  1.98978186e-01  2.54277792e-03\n",
      "  1.79365668e-02  1.37414619e-01 -3.17285091e-01  3.05866361e-01\n",
      " -5.12970030e-01 -2.61275142e-01 -9.35102701e-02  1.79125428e-01\n",
      " -2.10391685e-01 -1.50883906e-02  4.40478623e-01 -1.41883299e-01\n",
      " -1.85580269e-01  2.74730563e-01 -5.63141644e-01 -2.12939680e-02\n",
      "  3.02858710e-01  1.40549049e-01  3.89127910e-01  2.56754428e-01\n",
      "  3.43771964e-01  4.28193599e-01 -1.71352923e-01 -3.31032015e-02\n",
      " -4.26318496e-01 -2.93390065e-01 -9.01057478e-03  5.53740337e-02\n",
      "  9.81644094e-02  1.14478521e-01  1.30819589e-01 -1.47590162e-02\n",
      "  3.60918194e-01 -3.54843497e-01 -9.08831730e-02  1.02079391e-01\n",
      "  3.80571224e-02 -3.08976114e-01 -3.56378973e-01  3.11809003e-01\n",
      " -1.79365307e-01 -2.29618195e-02 -9.60443690e-02  1.88668653e-01\n",
      "  3.02370667e-01  5.18716983e-02  5.51617622e-01 -1.44471526e-01\n",
      " -3.08146447e-01 -2.24499837e-01  3.14181864e-01 -2.05274776e-01\n",
      "  4.67010170e-01 -3.95522922e-01  1.63495079e-01 -3.20937037e-01\n",
      " -2.64729559e-02 -5.04168808e-01  3.18555050e-02  3.05414975e-01\n",
      " -4.35881466e-01  1.46007920e-02  1.72290012e-01 -1.18597120e-01\n",
      " -6.95224822e-01  1.84633613e-01  1.15590535e-01  1.21813312e-01\n",
      "  7.04586506e-02  1.45597473e-01 -3.21627744e-02  1.71697646e-01\n",
      "  2.91679949e-01  2.29208961e-01  1.27947805e-02 -1.73981667e-01\n",
      "  6.02307022e-01  3.47406209e-01  1.83602631e-01 -3.77109557e-01\n",
      " -1.58993751e-01 -4.90773797e-01  9.34070945e-02  3.63557398e-01\n",
      " -3.62859577e-01  1.41519263e-01  1.49251409e-02 -3.91387418e-02\n",
      "  5.58443889e-02 -5.08337803e-02 -2.64987975e-01 -2.72801667e-01\n",
      "  1.01318136e-01 -6.57811105e-01 -2.52038300e-01 -1.96253017e-01\n",
      " -4.99508709e-01 -2.60050260e-02 -3.15849602e-01  6.49918854e-01\n",
      " -1.93839356e-01  3.46176848e-02 -4.18687686e-02  1.47541627e-01\n",
      " -2.43974715e-01  6.35896474e-02  5.04121065e-01 -3.08495760e-01\n",
      " -3.49465162e-01  1.45040795e-01  8.73226225e-02 -8.24881643e-02\n",
      "  9.53252092e-02  4.00853604e-02  4.15394008e-01  5.74999034e-01\n",
      "  2.08360150e-01  1.94468021e-01 -2.18329087e-01  2.89578944e-01\n",
      " -3.05583149e-01  2.84469128e-01 -2.40838304e-01  1.11983411e-01\n",
      "  2.77076423e-01 -5.66569390e-03  9.59814806e-03 -3.65130752e-01\n",
      "  3.20104882e-02  4.60759588e-02 -1.07880294e+00 -3.08452636e-01\n",
      "  3.28855217e-01 -7.36155868e-01  3.80772591e-01 -7.42518544e-01\n",
      " -2.65834481e-01  4.46573228e-01 -1.41769320e-01  1.24908537e-01\n",
      " -2.03675386e-02 -5.46289496e-02  4.25252020e-01  7.09130913e-02\n",
      "  2.88994402e-01 -2.08502710e-01  3.28392386e-01 -9.24268067e-02\n",
      "  4.31304157e-01 -3.64015281e-01 -1.76671371e-01  3.59446853e-01\n",
      "  3.48980576e-02 -1.42724231e-01 -4.70411070e-02 -3.81935686e-01\n",
      " -3.48947197e-02 -1.38373151e-01  9.22735594e-03 -3.67091686e-01\n",
      "  1.62303280e-02  3.37008908e-02 -5.31442277e-02  2.87000507e-01\n",
      " -7.50259385e-02 -3.11837435e-01 -1.44065574e-01 -1.15611464e-01\n",
      "  9.25036222e-02  2.86332220e-02 -3.73491682e-02 -1.76638559e-01\n",
      "  4.18306321e-01  7.40032196e-02  1.66652441e-01 -7.76644945e-01\n",
      "  9.41981748e-02  3.14192653e-01 -6.04671314e-02  4.98570092e-02\n",
      "  1.81243792e-01  1.64673194e-01  4.00068015e-01  7.29081705e-02\n",
      " -2.59922087e-01 -3.95336375e-02  2.25217883e-02 -2.80594528e-02\n",
      "  1.05179891e-01  1.00040540e-01  2.86649279e-02 -8.54152739e-02\n",
      " -3.96191239e-01  3.38525176e-01  3.86778921e-01  2.81567350e-02\n",
      "  1.83409482e-01  3.51889998e-01 -1.19160146e-01  4.59698945e-01\n",
      " -2.30247900e-01 -8.29263479e-02 -1.16330981e-01  3.55526805e-02\n",
      " -5.44659972e-01  3.89491200e-01 -3.23005646e-01 -3.11368734e-01\n",
      " -1.86718360e-01 -4.49822068e-01  1.83444649e-01  2.68363684e-01\n",
      "  4.11383748e-01 -2.09964171e-01 -2.37840891e-01 -3.58656287e-01\n",
      "  6.74625263e-02 -1.21710643e-01  4.46282439e-02 -4.97633964e-03\n",
      " -5.89461997e-02  2.55390376e-01 -2.38089740e-01  4.18233603e-01\n",
      " -4.67296422e-01  6.35878980e-01  2.52360642e-01  8.34834389e-03\n",
      "  2.87370920e-01 -1.16807610e-01  8.14501569e-02 -1.91247895e-01\n",
      "  2.30677962e-01 -2.20084250e-01 -6.02102101e-01 -1.96563974e-01\n",
      "  3.05674076e-01 -1.35688722e-01  4.56018001e-01 -1.09730281e-01\n",
      " -5.51245868e-01 -4.15686220e-02 -6.95373043e-02  2.13593438e-01\n",
      "  3.74401182e-01  3.60416174e-01  1.70816362e-01  9.95033234e-02\n",
      "  1.85536548e-01  3.09752207e-02  3.77041906e-01 -9.99226943e-02\n",
      "  3.61731768e-01 -8.46642852e-02  2.91310072e-01 -9.86162294e-03]\n"
     ]
    }
   ],
   "source": [
    "# Now to get word vectors out, just index into w2v.wv!\n",
    "print(w2v.wv[\"arrive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04dea4e8-ef53-471c-b44e-eea735dbb65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8729e2f67b6441fe88d253170c5e4558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842bb9259f67488c83066f609506a965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6e86ba58c04019aad7748038003806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocess our texts, apply the word-level vectorization,\n",
    "# and represent each document as just the elementwise sum\n",
    "# of its word vectors.\n",
    "\n",
    "def vectorize(df, vectors):\n",
    "    # we'll be fancy and do this with generators\n",
    "    texts = df[\"review_body\"].progress_apply(tokenize, nlp=nlp)\n",
    "    \n",
    "    # remove any words that didn't make it into the word2vec vocab\n",
    "    texts = (\n",
    "        [tok for tok in doc if tok in vectors.wv.key_to_index]\n",
    "        for doc in texts\n",
    "    )\n",
    "    \n",
    "    # get vectors and stack them into a single array\n",
    "    texts = np.array([\n",
    "        np.mean(w2v.wv[doc], axis=0)\n",
    "        if len(doc) > 0\n",
    "        else np.zeros(300)\n",
    "        for doc in texts\n",
    "    ])\n",
    "    \n",
    "    return texts\n",
    "\n",
    "train_docs = vectorize(train, w2v)\n",
    "test_docs = vectorize(test, w2v)\n",
    "val_docs = vectorize(val, w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e136e82-367b-484b-9f9c-4b08ff6d9731",
   "metadata": {},
   "source": [
    "Note that if a document didn't have any words that made it into the Word2Vec vectors, we're just giving that document an all-zero vector rather than dropping it. \n",
    "\n",
    "Now, we can just throw this same data into our neural network from before and see how it goes.  (I'm going to be bad and just copy-paste from before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "654dcc0e-536d-40ad-aac4-c32c70579667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50de855a10d84786a62499f56c9a7173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.145728 - val_acc=50.700% - val_f1=0.505186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecef58c7b844c1d9d990c6bba8b389a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.128368 - val_acc=50.640% - val_f1=0.493484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087d86532dfd47b482271215ff30c5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.123204 - val_acc=50.800% - val_f1=0.500298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0617e08eac974fd385156b9ac2604d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.111543 - val_acc=51.540% - val_f1=0.508853\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0c308b0348489492d427f9bfccc5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.110667 - val_acc=51.820% - val_f1=0.511567\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22df5290b1f8466380d8267d67939f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.120491 - val_acc=51.680% - val_f1=0.511343\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20b193102754727a74754b6d94824e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.119671 - val_acc=51.680% - val_f1=0.512154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16612d0bdc664603bec1db4f9c8750ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.122806 - val_acc=51.160% - val_f1=0.507976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad02885e454f468a9ae0b15dd9ffb2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.120328 - val_acc=51.340% - val_f1=0.507619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfd70e0916e4eb78b3372cb61a24aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=1.139545 - val_acc=50.480% - val_f1=0.501121\n",
      "Final test set scores: accuracy=50.48%, f1=0.5011\n"
     ]
    }
   ],
   "source": [
    "train_torch = prepare_dataset(train_docs, train)\n",
    "test_torch = prepare_dataset(test_docs, test)\n",
    "val_torch = prepare_dataset(val_docs, val)\n",
    "\n",
    "# model specification\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.BatchNorm1d(300),\n",
    "    torch.nn.Linear(300, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 5),\n",
    ")\n",
    "model.to(DEVICE)\n",
    "model = training_loop(model, train_torch, val_torch)\n",
    "\n",
    "# final performance metrics\n",
    "model.eval()\n",
    "preds = []\n",
    "ys = []\n",
    "for (x, y) in val_torch:\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    preds.append(model(x).to(\"cpu\").detach().numpy())\n",
    "    ys.append(y.to(\"cpu\"))\n",
    "preds = np.argmax(np.vstack(preds), axis=1)\n",
    "ys = np.argmax(np.vstack(ys), axis=1)\n",
    "\n",
    "acc = np.mean(preds == ys)\n",
    "f1 = f1_score(preds, ys, average=\"macro\")\n",
    "print(f\"Final test set scores: accuracy={acc:.2%}, f1={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90d85da-75f5-4225-9848-051cde88d40c",
   "metadata": {},
   "source": [
    "The difference here is pretty small compared to using spaCy's pre-trained vectors--just a small increase in accuracy/F1--but we also didn't bother to do any parameter tuning for the Word2Vec algorithm itself (which we would/should do in a serious production use case).  And our language is pretty \"normal\" English.  If we were working in a really specialized or unusual linguistic domain, the difference might be a lot bigger.  Plus, the spaCy developers train their vectors against a _huge_ corpus of text (specifically Common Crawl), so it's going to be hard to blow them out of the water with just a few hundred thousand short reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae909d7f-3c64-4400-8d24-420d3c1a0ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
