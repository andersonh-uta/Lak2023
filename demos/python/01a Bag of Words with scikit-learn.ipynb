{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a09ba83-fbc9-46fe-85eb-33fcb6ea06b5",
   "metadata": {},
   "source": [
    "# Python demo: Bag-of-Words modeling entirely in `scikit-learn`\n",
    "\n",
    "Bag-of-words should always be in your back pocket.  There will basically never be a situation where bag-of-word gives you no results, but more complex models do.  Usually, the bag-of-words model will at least give you _something_ as long as your task can be said to depend on the _meaning of the words in the text._  Bag-of-words also allows you a lot of opportunities to inject expert and domain knowledge into the modeling process, which we'll see in the notebooks that follow this one.\n",
    "\n",
    "Bag-of-words involves us representing our documents as _vectors of word counts._  I.e.: our _features_ are \"what words do you use, and how often do you use them?\"  Bag-of-words ignored things like word order, syntactic relationships, etc.; while such things can definitely provide some useful information, a lot of real-world tasks will see pretty aggressively diminishing returns from them.\n",
    "\n",
    "This notebook will show the most quick-and-dirty way to do bag-of-words models in Python: using `scikit-learn`'s `CoutnVectorizer()`.\n",
    "\n",
    "Pros:\n",
    "- Extremely simple code--just a few lines to get a whole model up and running.\n",
    "- Often surprisingly accurate for many tasks, despite its simplicity.  This makes a scikit-learn pipeline an excellent \"first attempt\" at a text problem, or a great baseline to compare more sophisticated models against.\n",
    "- Very fast (with the right choice of model, e.g. Naive Bayes, as we're using here).\n",
    "\n",
    "Cons:\n",
    "- Not a lot of fine-grained control, which usually leads to leaving accuracy on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b9049a-b872-49e7-9dd0-2aaa859cbe1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T23:59:17.722493Z",
     "iopub.status.busy": "2023-03-02T23:59:17.722493Z",
     "iopub.status.idle": "2023-03-02T23:59:17.733495Z",
     "shell.execute_reply": "2023-03-02T23:59:17.733495Z"
    }
   },
   "outputs": [],
   "source": [
    "# requirements\n",
    "# !conda install --yes pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f04ee310-bd30-4ae3-91a6-71a6abcb7cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T23:59:17.736490Z",
     "iopub.status.busy": "2023-03-02T23:59:17.736490Z",
     "iopub.status.idle": "2023-03-02T23:59:19.210614Z",
     "shell.execute_reply": "2023-03-02T23:59:19.209777Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_0964290</td>\n",
       "      <td>product_en_0740675</td>\n",
       "      <td>reviewer_en_0342986</td>\n",
       "      <td>1</td>\n",
       "      <td>Arrived broken. Manufacturer defect. Two of th...</td>\n",
       "      <td>I'll spend twice the amount of time boxing up ...</td>\n",
       "      <td>en</td>\n",
       "      <td>furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_0690095</td>\n",
       "      <td>product_en_0440378</td>\n",
       "      <td>reviewer_en_0133349</td>\n",
       "      <td>1</td>\n",
       "      <td>the cabinet dot were all detached from backing...</td>\n",
       "      <td>Not use able</td>\n",
       "      <td>en</td>\n",
       "      <td>home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_0311558</td>\n",
       "      <td>product_en_0399702</td>\n",
       "      <td>reviewer_en_0152034</td>\n",
       "      <td>1</td>\n",
       "      <td>I received my first order of this product and ...</td>\n",
       "      <td>The product is junk.</td>\n",
       "      <td>en</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_0044972</td>\n",
       "      <td>product_en_0444063</td>\n",
       "      <td>reviewer_en_0656967</td>\n",
       "      <td>1</td>\n",
       "      <td>This product is a piece of shit. Do not buy. D...</td>\n",
       "      <td>Fucking waste of money</td>\n",
       "      <td>en</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en_0784379</td>\n",
       "      <td>product_en_0139353</td>\n",
       "      <td>reviewer_en_0757638</td>\n",
       "      <td>1</td>\n",
       "      <td>went through 3 in one day doesn't fit correct ...</td>\n",
       "      <td>bubble</td>\n",
       "      <td>en</td>\n",
       "      <td>pc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id          product_id          reviewer_id  stars  \\\n",
       "0  en_0964290  product_en_0740675  reviewer_en_0342986      1   \n",
       "1  en_0690095  product_en_0440378  reviewer_en_0133349      1   \n",
       "2  en_0311558  product_en_0399702  reviewer_en_0152034      1   \n",
       "3  en_0044972  product_en_0444063  reviewer_en_0656967      1   \n",
       "4  en_0784379  product_en_0139353  reviewer_en_0757638      1   \n",
       "\n",
       "                                         review_body  \\\n",
       "0  Arrived broken. Manufacturer defect. Two of th...   \n",
       "1  the cabinet dot were all detached from backing...   \n",
       "2  I received my first order of this product and ...   \n",
       "3  This product is a piece of shit. Do not buy. D...   \n",
       "4  went through 3 in one day doesn't fit correct ...   \n",
       "\n",
       "                                        review_title language  \\\n",
       "0  I'll spend twice the amount of time boxing up ...       en   \n",
       "1                                       Not use able       en   \n",
       "2                               The product is junk.       en   \n",
       "3                             Fucking waste of money       en   \n",
       "4                                             bubble       en   \n",
       "\n",
       "   product_category  \n",
       "0         furniture  \n",
       "1  home_improvement  \n",
       "2              home  \n",
       "3          wireless  \n",
       "4                pc  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "train = pd.read_csv(\"../../data/train.csv\")\n",
    "test = pd.read_csv(\"../../data/test.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c1596-5277-4daa-8b50-674f1485d59e",
   "metadata": {},
   "source": [
    "`scikit-learn` has three main tools for doing the text-to-vector conversion:\n",
    "- `sklearn.feature_extraction.text.CountVectorizer`, which represents each document as a vector of word counts.\n",
    "- `sklearn.feature_extraction.text.TfidfVectorizer` and `TfidfTransformer`: applies Term Frequency-Inverse Document Frequency scaling, which can help improve accuracy for some models.  (`TfidfVectorizer` is the same thing as `CountVectorizer` followed by `TfidfTransformer`).\n",
    "- `sklearn.feature_extraction.text.HashingVectorizer`: a version of `CountVectorizer` that uses the hashing trick to map directly from words to columns.  This can be a _lot_ faster for extremely large datasets, but it can also lead to _hash collisions_ where several words get mapped to to the same feature/column.\n",
    "\n",
    "We're just going to use `CountVectorizer`--feel free to swap it out for `TfidfVectorizer` or `HashingVectorizer` on your on and see how the results change.  We're also going to use a Bernoulli Naive Bayes model to do the classification, since it's extremely fast even on massive, sparse datasets, and it'll be accurate enough.  Feel free to swap this out for any other models, but just be aware that the large sparse matrices we get from bag-of-words transformations tend to make most models run very slow.  (especially with multi-class classification like we're doing here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acecf06-ade3-47fd-829f-cb14f58500e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T23:59:19.212663Z",
     "iopub.status.busy": "2023-03-02T23:59:19.212663Z",
     "iopub.status.idle": "2023-03-02T23:59:19.985330Z",
     "shell.execute_reply": "2023-03-02T23:59:19.984329Z"
    }
   },
   "outputs": [],
   "source": [
    "# first: a helper function to absract the \"fit + predict + score\" logic.\n",
    "from sklearn import metrics\n",
    "\n",
    "def fit_and_score(clf, train, test):\n",
    "    \"\"\"fit the model `clf` to the `train` dataset and evaluate its\n",
    "    performance on the `test` dataset.\"\"\"\n",
    "    clf.fit(train[\"review_body\"], train[\"stars\"])\n",
    "    preds = clf.predict(test[\"review_body\"])\n",
    "    \n",
    "    # calculate some classification metrics\n",
    "    accuracy = metrics.accuracy_score(preds, test[\"stars\"])\n",
    "    f1 = metrics.f1_score(preds, test[\"stars\"], average=\"macro\")\n",
    "\n",
    "    # and some regression metrics (since \"predict the number of stars\"\n",
    "    # could reasonably be either kind of task).\n",
    "    r2 = metrics.r2_score(preds, test[\"stars\"])\n",
    "    mae = metrics.mean_absolute_error(preds, test[\"stars\"])\n",
    "    \n",
    "    return pd.Series({\"Accuracy\": accuracy, \"F1\": f1, \"R2\": r2, \"MAE\": mae})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef27012-553f-44bb-bec5-47fa10de9dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T23:59:19.992327Z",
     "iopub.status.busy": "2023-03-02T23:59:19.991326Z",
     "iopub.status.idle": "2023-03-02T23:59:24.565417Z",
     "shell.execute_reply": "2023-03-02T23:59:24.564642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy    0.453400\n",
       "F1          0.433647\n",
       "R2          0.315741\n",
       "MAE         0.857600\n",
       "Name: Bag of Words + Linear kernel SVM, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# This is it--this is our pipeline.  CountVectorizer--dropping words\n",
    "# that appears in >50% of our documents or <10 documents--followed\n",
    "# by a Bernoulli Naive Bayes model.  Super simple, and super fast.\n",
    "classifier = Pipeline([\n",
    "    (\"bag of words\", CountVectorizer(max_df=0.5, min_df=10)),\n",
    "    (\"clf\", BernoulliNB()),\n",
    "])\n",
    "fit_and_score(classifier, train, test).rename(\"Bag of Words + Linear kernel SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d94031-b41b-48f8-a5d3-7cd6eaac7afd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T23:59:24.567450Z",
     "iopub.status.busy": "2023-03-02T23:59:24.567450Z",
     "iopub.status.idle": "2023-03-02T23:59:24.979425Z",
     "shell.execute_reply": "2023-03-02T23:59:24.978628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy    0.198800\n",
       "F1          0.198675\n",
       "R2         -0.975752\n",
       "MAE         1.605800\n",
       "Name: Dummy Classifier, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a dummy classifier to check how much better than a random guess\n",
    "# we are.\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifier = GridSearchCV(\n",
    "    DummyClassifier(),\n",
    "    param_grid={\"strategy\": [\"most_frequent\", \"prior\", \"stratified\", \"uniform\"]}\n",
    ")\n",
    "fit_and_score(classifier, train, test).rename(\"Dummy Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c70ac-f41f-4fe4-82f6-dd46e36fc3ba",
   "metadata": {},
   "source": [
    "`scikit-learn` has a lot of option you can specify for the `CountVectorizer()` object.  You can filter tokens by frequency, apply stemming, capture n-grams, remove stopwords, etc.\n",
    "\n",
    "As compact as the scikit-learn approach is, though, it wraps _all_ the language-y bits up in the `CountVectorizer()` and its options; we don't get a huge amont of freedom to muck around with the internals.  This is where we can use other libaries like Gensim and spaCy, which we'll see in the next notebook.\n",
    "\n",
    "Despite its simplicity, this two-step pipeline we've used here is always a good tool to bust out for quick-and-dirty checks and testing.  It's fast, simple, and will usually give you a good baseline for model performance.  (though you should still always double-check against a dummy model to make sure you're doing better than a random guess)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
