{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ca8d54-75b3-418a-9f81-c18a5949950b",
   "metadata": {},
   "source": [
    "# Bag of Words in Julia\n",
    "\n",
    "Julia is a very exciting new programming language that you should definitely check out, especially if you're a heavy Python user who wants more speed out of your code.  Julia's NLP ecosystem isn't as mature as Python's or R's yet, so expect some rough edges, and expect to re-implement a lot of stuff yourself.  Julia is designed less around large, monolithic libaries (like Python's `scikit-learn`), and more around small, _composable_ libraries that you combine piece-by-piece.  There's also a stronger culture of not re-inventing the wheel; if something can be implemented in a few lines of code by the end user, then it's more likely to be left out of the library.\n",
    "\n",
    "All this means: we'll need to do things like implementing a string-to-sparse matrix conversion ourself.  Fortunately this is pretty easy to do, as we'll see.\n",
    "\n",
    "Note: I'll be using a lot of semicolons after the last line of each cell.  In Julia, assignment operations return the assigned value, and Jupyter wants to print that out.  A trailing semicolon after a line will suppress this otuput.  I'm also going to use type annotations pretty heavily--unnecessarily heavily, for anyone who's already a Julia programmer--just to make things more explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba43a695-52f9-4615-858e-835ea8fa0ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `C:\\Users\\andersonh\\Documents\\UA Projects\\LAK 2023\\demos\\julia`\n"
     ]
    }
   ],
   "source": [
    "# Julia uses the Pkg module of its standard library to do project-specific\n",
    "# package dependencies.  This is like `renv` in R, and kind of like the various\n",
    "# (non-conda) virtual environments in Python.\n",
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd45983-150d-4c86-ba43-a318efa582e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell if you need to install the dependencies, otherwise skip it\n",
    "# Pkg.add(\"CSV\")            # parse CSV files\n",
    "# Pkg.add(\"DataFrames\")     # dataframes\n",
    "# Pkg.add(\"MLJ\")            # general machine learning framework\n",
    "# Pkg.add(\"MLJScikitLearnInterface\") # interface to scikit-learn, so we can use sklearn models\n",
    "# Pkg.add(\"Pipe\")           # macros for better piping syntax\n",
    "# Pkg.add(\"ProgressMeter\")  # progress bars\n",
    "# Pkg.add(\"Snowball\")       # interface to the Snowball stemming libary\n",
    "# Pkg.add(\"WordTokenizers\") # some common tokenization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0df5a8f-cdad-405f-8c6c-59d257027640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data.  This step will take a while the first time \n",
    "# you run it, while Julia pre-compiles things.\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "train = DataFrame(CSV.File(\"../../data/train.csv\"))\n",
    "test = DataFrame(CSV.File(\"../../data/test.csv\"))\n",
    "val = DataFrame(CSV.File(\"../../data/validation.csv\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d539101-4881-458d-afec-42dc61f6504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10×8 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m review_id  \u001b[0m\u001b[1m product_id         \u001b[0m\u001b[1m reviewer_id         \u001b[0m\u001b[1m stars \u001b[0m\u001b[1m review_body                       \u001b[0m\u001b[1m review_title                      \u001b[0m\u001b[1m language \u001b[0m\u001b[1m product_category    \u001b[0m\n",
      "     │\u001b[90m String15   \u001b[0m\u001b[90m String31           \u001b[0m\u001b[90m String31            \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m String                            \u001b[0m\u001b[90m String                            \u001b[0m\u001b[90m String3  \u001b[0m\u001b[90m String31            \u001b[0m\n",
      "─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │ en_0964290  product_en_0740675  reviewer_en_0342986      1  Arrived broken. Manufacturer def…  I'll spend twice the amount of t…  en        furniture\n",
      "   2 │ en_0690095  product_en_0440378  reviewer_en_0133349      1  the cabinet dot were all detache…  Not use able                       en        home_improvement\n",
      "   3 │ en_0311558  product_en_0399702  reviewer_en_0152034      1  I received my first order of thi…  The product is junk.               en        home\n",
      "   4 │ en_0044972  product_en_0444063  reviewer_en_0656967      1  This product is a piece of shit.…  Fucking waste of money             en        wireless\n",
      "   5 │ en_0784379  product_en_0139353  reviewer_en_0757638      1  went through 3 in one day doesn'…  bubble                             en        pc\n",
      "   6 │ en_0420650  product_en_0705898  reviewer_en_0155342      1  Poor quality. The material was f…  Poor quality. The material was f…  en        industrial_supplies\n",
      "   7 │ en_0206383  product_en_0041998  reviewer_en_0005698      1  Ordered 2 they shipped 1 promise…  Not reliable ☹️                     en        home\n",
      "   8 │ en_0638563  product_en_0523280  reviewer_en_0363065      1  Followed directions, did not wor…  Waste of money                     en        kitchen\n",
      "   9 │ en_0331944  product_en_0737171  reviewer_en_0434580      1  There is a terribly done band ac…  Picture Doesn’t Represent Well     en        apparel\n",
      "  10 │ en_0220290  product_en_0912236  reviewer_en_0514794      1  Unless you have this jam-packed …  Collapses on itself                en        automotive\n"
     ]
    }
   ],
   "source": [
    "println(train[1:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf31ab7-1572-49d6-a069-37bc3c732ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mPreprocessing training data 100%|████████████████████████| Time: 0:00:10\u001b[39m:39\u001b[39mm\n",
      "\u001b[32mPreprocessing testing data 100%|█████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54-element Vector{String}:\n",
       " \"arriv\"\n",
       " \"broken\"\n",
       " \"manufactur\"\n",
       " \"defect\"\n",
       " \"two\"\n",
       " \"leg\"\n",
       " \"base\"\n",
       " \"complet\"\n",
       " \"form\"\n",
       " \"way\"\n",
       " \"insert\"\n",
       " \"caster\"\n",
       " \"unpackag\"\n",
       " ⋮\n",
       " \"miss\"\n",
       " \"though\"\n",
       " \"hesit\"\n",
       " \"buy\"\n",
       " \"make\"\n",
       " \"wonder\"\n",
       " \"miss\"\n",
       " \"structur\"\n",
       " \"support\"\n",
       " \"imped\"\n",
       " \"assembl\"\n",
       " \"process\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pipe\n",
    "using ProgressMeter\n",
    "using Snowball\n",
    "\n",
    "const STOPWORDS = map(\n",
    "    x -> stem(Stemmer(\"english\"), x),\n",
    "    split(\"\"\"i me my myself we our ours ourselves you your yours yourself yourselves he him his himself she her hers herself it its itself they them their theirs themselves what which who whom this that these those am is are was were be been being have has had having do does did doing a an the and but if or because as until while of at by for with about against between into through during before after above below to from up down in out on off over under again further then once here there when where why how all any both each few more most other some such no nor not only own same so than too very s t can will just don should now aren isn weren\"\"\")\n",
    ")\n",
    "\n",
    "# A simple preprocessing function that generally looks like Gensim's default\n",
    "# preprocessing steps.\n",
    "preprocess(s::String, stemmer::Stemmer) :: Vector{String} = @pipe (\n",
    "    s\n",
    "    |> lowercase(_)\n",
    "    |> replace(_, r\"[^a-z]+\" => \" \")\n",
    "    |> split(_)\n",
    "    |> map(x -> stem(stemmer, x), _)\n",
    "    |> filter(x -> length(x) >= 3, _)\n",
    "    |> filter(x -> !(x in STOPWORDS), _)\n",
    ")\n",
    "\n",
    "train_tokens = @showprogress \"Preprocessing training data\" [\n",
    "     preprocess(i, Stemmer(\"english\")) for i in train[!, :review_body]\n",
    "]\n",
    "test_tokens = @showprogress \"Preprocessing testing data\" [\n",
    "     preprocess(i, Stemmer(\"english\")) for i in test[!, :review_body]\n",
    "]\n",
    "\n",
    "train_tokens[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ad4b7-4dd6-48a3-8bcb-136132fce643",
   "metadata": {},
   "source": [
    "We can re-implement a document frequency filter pretty compactly.  This will replicate the general functionality of `gensim.Dictionary` and `gensim.Dictionary.filter_extremes()` from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51eb401-79c2-4d8f-b54a-670384a01090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count how many times each token appears across\n",
    "# the corpus.  `iterable` is e.g. an array of array of strings.\n",
    "function counter(iterable)\n",
    "    counts = Dict()\n",
    "    for i ∈ iterable\n",
    "        counts[i] = get(counts, i, 0) + 1\n",
    "    end\n",
    "    return counts\n",
    "end\n",
    "\n",
    "function remove_extreme!(counts::Dict, threshold::Number, comparison::Function)\n",
    "    if threshold < 1\n",
    "        threshold = sum(values(counts)) * threshold\n",
    "    end\n",
    "    \n",
    "    for (k, v) ∈ pairs(counts)\n",
    "        if comparison(v, threshold)\n",
    "            delete!(counts, k)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "remove_frequent!(counts, thresh) = remove_extreme!(counts, thresh, >)\n",
    "remove_rare!(counts, thresh) = remove_extreme!(counts, thresh, <)\n",
    "\n",
    "# to get document frequencies, convert each document to a Set()--which\n",
    "# deduplicates entries--and then run the Counter.\n",
    "word_counts = counter(tok for doc ∈ train_tokens for tok ∈ Set(doc))\n",
    "remove_frequent!(word_counts, 0.5)\n",
    "remove_rare!(word_counts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de45218-4a35-4691-8526-600ddbaafd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7704, 200000)\n",
      "(7704, 5000)\n"
     ]
    }
   ],
   "source": [
    "# bag of words matrix time!  Need to convert word into row indices\n",
    "# and documents into columns (Julia arrays are column-first, unlike\n",
    "# Python/R which are row-first).\n",
    "using SparseArrays\n",
    "\n",
    "# Use a dict of token => index mappings to convert a document into a\n",
    "# vector of row indices.  This will drop any tokens not in the `ocab`\n",
    "# dict.\n",
    "function doc2bow(vocab::Dict{String, Int}, doc::Vector{String}) :: Dict{Int, Int}\n",
    "    return Dict(\n",
    "        vocab[tok] => count\n",
    "        for (tok, count) in counter(doc)\n",
    "        if tok ∈ keys(vocab)\n",
    "    )\n",
    "end\n",
    "\n",
    "function tokens2bow(vocab::Dict{String, Int}, docs::Vector{Vector{String}}) :: SparseMatrixCSC\n",
    "    # convert each document into a dict of token_index => count pairs\n",
    "    bow = [doc2bow(vocab, doc) for doc ∈ docs]\n",
    "\n",
    "    # set up the \"internal\" arrays for the sparse matrix.\n",
    "    # This is a pretty standard sparse matrix format, but you\n",
    "    # may need to read some documentation for it to make sense\n",
    "    # if you haven't seen it before.\n",
    "    colptr = zeros(Int, length(bow) + 1)\n",
    "    rowval = zeros(Int, sum(length.(bow)))\n",
    "    nzval  = zeros(UInt16, sum(length.(bow)))\n",
    "    colptr[1] = 1\n",
    "    \n",
    "     # indices that we'll advance through as we update the above arrays\n",
    "    rowval_ptr = 1\n",
    "    colptr_ptr = 2\n",
    "    \n",
    "    # update the colptr/rowval arrays\n",
    "    for doc in bow\n",
    "        for (row_idx, val) in doc\n",
    "            rowval[rowval_ptr] = row_idx\n",
    "            nzval[rowval_ptr] = val\n",
    "            rowval_ptr += 1\n",
    "            colptr[colptr_ptr] += 1\n",
    "            # println(\"[$row_idx, $(colptr_ptr-1)]=$val\")\n",
    "        end\n",
    "        colptr_ptr += 1\n",
    "    end\n",
    "    \n",
    "    return SparseMatrixCSC(\n",
    "        length(vocab),\n",
    "        length(bow),\n",
    "        cumsum(colptr),\n",
    "        rowval,\n",
    "        nzval,\n",
    "    )\n",
    "end\n",
    "\n",
    "# token-to-index mapping\n",
    "vocab = Dict(j => i for (i, j) in enumerate(keys(word_counts)))\n",
    "\n",
    "train_bow = tokens2bow(vocab, train_tokens)\n",
    "test_bow = tokens2bow(vocab, test_tokens)\n",
    "\n",
    "println(size(train_bow))\n",
    "println(size(test_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdab1a8-bd5f-4e03-a317-b880bcb7f279",
   "metadata": {},
   "source": [
    "We could use `ScikitLearn.jl`, which provides a direct interface to scikit-learn models.  But as of writing this (early 2023), ScikitLearn.jl still has pretty bad support for sparse matrices.  It'll tend to convert them to dense matrices, which is bad--it'll cause our memory usage to explode.\n",
    "\n",
    "So instead, we'll use a Decision Tree from the DecisionTree.jl package (via the MLJ.jl interface, which wraps DecisionTree.jl and a lot of other libraries in a nicer interface), which will support sparse feature arrays.  But since this takes a long time to run--decision trees are generally slow when there are very large numbers of features--we'll also throw in some Singular Value Decomposition to reduce our number of features down to a more reasonable 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ae4094-42b3-4258-a997-680d93f431e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\andersonh\\.julia\\packages\\MLJModels\\8Nrhi\\src\\loading.jl:159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\andersonh\\.julia\\packages\\MLJModels\\8Nrhi\\src\\loading.jl:159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJTSVDInterface ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "untrained Machine; does not cache data\n",
       "  model: ProbabilisticPipeline(tsvd_transformer = TSVDTransformer(nvals = 300, …), …)\n",
       "  args: \n",
       "    1:\tSource @896 ⏎ AbstractMatrix{Continuous}\n",
       "    2:\tSource @005 ⏎ AbstractVector{Multiclass{5}}\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLJ\n",
    "\n",
    "model = @load DecisionTreeClassifier pkg=DecisionTree\n",
    "svd = @load TSVDTransformer pkg=TSVD\n",
    "model = machine(\n",
    "    Pipeline(svd(nvals=300), model()),\n",
    "    coerce(transpose(train_bow), Continuous),\n",
    "    coerce(train[!, :stars], Multiclass),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683a3a0-415a-470b-93b9-c8f250bf0e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(ProbabilisticPipeline(tsvd_transformer = TSVDTransformer(nvals = 300, …), …), …).\n",
      "└ @ MLJBase C:\\Users\\andersonh\\.julia\\packages\\MLJBase\\uxwHr\\src\\machines.jl:492\n",
      "┌ Info: Training machine(:tsvd_transformer, …).\n",
      "└ @ MLJBase C:\\Users\\andersonh\\.julia\\packages\\MLJBase\\uxwHr\\src\\machines.jl:492\n"
     ]
    }
   ],
   "source": [
    "fit!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a4036-92d0-445b-9fd0-d63de0dbef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model, coerce(transpose(test_bow), Continuous));\n",
    "println(preds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f6d40b-ca4b-4b57-9b98-a5285dcf468b",
   "metadata": {},
   "source": [
    "The predictions are a `UnivariateFinite` type--which is actually a kind of distribution.  This intuitively makes a lot of sense, ince a (pseudo-)probabilistic prediction is basically just a distribution over possible classes.  To convert these to a hard-margin classification we can just call the `mode` function, which extract the value with the highest probability mass from the distribution.  This returns a `CategoricalValue`--which is part of the `CategoricalArrays` library that handles categorical data, but we can just directly compare to our various integer class labels and not worry about this.  Unless we want to treat the predictions as numbers, e.g. for calculating an $r^2$ or Mean Absolute Error score.  In those cases we can just use the `unwrap()` function from `CategoricalValues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a093d-3571-494c-9842-1b96b1975850",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CategoricalArrays\n",
    "\n",
    "preds = mode.(preds)\n",
    "println(\"\"\"\n",
    "    Accuracy: $(mean(preds .== test[!, :stars]))\n",
    "    Macro F1: $(macro_f1score(preds, test[!, :stars]))\n",
    "    R^2:      $(rsq(unwrap.(preds), test[!, :stars]))\n",
    "    MAE:      $(mean(abs.(unwrap.(preds) .- test[!, :stars])))\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e93ec6-f1ca-4ca4-81fd-f4e2c8516559",
   "metadata": {},
   "source": [
    "This model did quite a lot worse than the `BernoulliNB` from `scikit-learn`, but then again, we did have to do some extra steps due to still-poor Sparse Array support in Julia's ML libraries.  But there are some very cool machine learning libaries we could have used instead, like `Flux.jl`, which lets us write very Pytorch-like neural networks, or `SimpleChains.jl` for extremely fast implementations of simpler neural network architectures.  (the kind you'd get from only using, e.g., `torch.Sequential` or `keras.Sequential` in Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231135f-d940-4543-8415-05b90d3d12c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
